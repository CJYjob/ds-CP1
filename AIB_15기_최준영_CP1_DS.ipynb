{"cells":[{"cell_type":"markdown","metadata":{"id":"6QCsVqzIo8mP"},"source":["# 0. Colab 기본 세팅"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2493,"status":"ok","timestamp":1673070601448,"user":{"displayName":"최준영","userId":"05341350750950124905"},"user_tz":-540},"id":"ovwnS1QWooFS","outputId":"d7c4f967-de4c-4928-9008-c43a4dcd4551"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# 구글 드라이브 마운트(cjyjob1993@gmail.com)\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N5oZijhxpDI4"},"outputs":[],"source":["# lib 디렉토리를을 환경 변수에 추가(lib 내 파일 변경 시, 런타임을 재시작 해주어야 변경 내용이 적용됨.)\n","import sys\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/CodeStates/CodeStates_Project_1/lib')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eVA69NhPeCit","executionInfo":{"status":"ok","timestamp":1673070601449,"user_tz":-540,"elapsed":12,"user":{"displayName":"최준영","userId":"05341350750950124905"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"34ca8c0a-ab88-4e29-cff1-8d7d3d07af63"},"outputs":[{"output_type":"stream","name":"stdout","text":["debug_log | 2023.01.07 05:50:00 | >>> start debug\n"]}],"source":["# debug를 위한 출력 모듈 임포트 (config.py의 debug_flag가 1이면, 디버그 내용 출력.)\n","import debugLog\n","from debugLog import debugLog\n","debugLog('start debug')"]},{"cell_type":"markdown","source":["# 1. 인공신경망 구현하기"],"metadata":{"id":"vHT_Ns5d82WC"}},{"cell_type":"markdown","source":["## [0] 기본 라이브러리 임포트"],"metadata":{"id":"s5Oawclh-1Bu"}},{"cell_type":"code","source":["# 사용 라이브러리 임포트\n","debugLog('기본 라이브러리 임포트')\n","import numpy as np\n","import pandas as pd\n","import csv\n","import matplotlib.pyplot as plt"],"metadata":{"id":"Ae-hwjQ1uZL8","executionInfo":{"status":"ok","timestamp":1673070601906,"user_tz":-540,"elapsed":464,"user":{"displayName":"최준영","userId":"05341350750950124905"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"15cb8247-c5c1-4eef-973e-4ef5e0d24e31"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["debug_log | 2023.01.07 05:50:00 | >>> 기본 라이브러리 임포트\n"]}]},{"cell_type":"code","source":["# dataframe 을 확인 시 편의를 위해, 출력 column 수 제한을 없앰\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.width', 1000)"],"metadata":{"id":"sA0Ei8ZuZp7-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## [1] 데이터 불러오기 기능"],"metadata":{"id":"8M1YA9iI_MCw"}},{"cell_type":"code","source":["def dataLoad() :\n","  debugLog(f'dataLoad() 를 시작합니다.')\n","  df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CodeStates/CodeStates_Project_1/binary_dataset.csv')\n","  debugLog(f'data 를 df 변수로 바인딩했습니다.')\n","  debugLog(f'dataLoad() 를 종료합니다. 반환값은 \\n\\tdf = \\n{df} \\n 입니다.')\n","  return df"],"metadata":{"id":"sb2mhSgp9wSU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## [2] 파라미터와 편향 생성 기능\n"],"metadata":{"id":"psdvhbzA_X-N"}},{"cell_type":"code","source":["def createPerceptron(df) :\n","  debugLog(f'createPerceptron() 를 시작합니다.')\n","  featuresNum = len(df.columns) - 1\n","  debugLog(f'입력받은 df의 feature 개수를 featuresNum 변수에 바인딩합니다.')\n","  weights = np.random.rand(featuresNum)\n","  debugLog(f'featuresNum의 수 만큼 weight 값을 난수(0~1 사이의 수)로 초기화합니다. 해당 값을 weights 변수로 바인딩합니다.')\n","  bias = np.random.rand(1)[0]\n","  debugLog(f'perceptron의 outputNode(1개) bias 값을 난수(0~1 사이의 수)로 초기화합니다. 해당 값을 bias 변수로 바인딩합니다.')\n","  debugLog(f'craetePerceptron() 을 종료합니다. 반환값은 \\n\\tWeights = {weights}, \\n\\tBias = {bias}) 입니다.')\n","  return weights, bias"],"metadata":{"id":"fzZMYZ4H_b_a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## [3] 데이터 뒤섞기 기능\n"],"metadata":{"id":"4fpHH7P__aVv"}},{"cell_type":"code","source":["def shuffleDf(df) :\n","  debugLog(f'shuffleDf() 를 시작합니다.')\n","  idx_i = df.index\n","  df = df.sample(frac=1) # shuffling\n","  idx_f = df.index\n","  df = df.reset_index(drop=True) # index reset\n","  debugLog(f'df를 shuffle하고 index를 초기화해 df로 재할당 합니다. 처리 전후 idx는 다음과 같습니다. \\n\\tidx_i : {list(idx_i)} \\n\\tidx_f : {list(idx_f)}')\n","  debugLog(f'shuffleDf() 를 종료합니다. 반환값은 shuffle된 df 입니다.')\n","  return df"],"metadata":{"id":"0UT1S1OM_cRy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## [4] 데이터 전처리"],"metadata":{"id":"c23SMGZgCmMv"}},{"cell_type":"markdown","source":["### [4-1] 데이터 라벨, 특징 분리 기능"],"metadata":{"id":"r8STmmCuX6e6"}},{"cell_type":"code","source":["def divideLabelFeature(df, label, features) :\n","  debugLog(f'divideLabelFeature() 를 시작합니다.')\n","  X = df[features]\n","  debugLog(f'features에 해당하는 데이터를 X 변수로 바인딩합니다.')\n","  y = df[label]\n","  debugLog(f'label에 해당하는 데이터를 y 변수로 바인딩합니다.')\n","  debugLog(f'divideLabelFeature() 를 종료합니다. 반환값은 \\n\\tfeatures = \\n{X} \\n\\tlabel = \\n{y}')\n","  return X, y"],"metadata":{"id":"gGmtfVt7YIJd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### [4-2] 노말라이제이션"],"metadata":{"id":"ZVi9V4KNCQ4G"}},{"cell_type":"code","source":["def normalize(df) :\n","  debugLog(f'normalize() 를 시작합니다.')\n","  debugLog(f'각 칼럼의 최댓값으로 열의 값들을 나눠 정규화합니다.')\n","  result = df.copy()\n","  debugLog(f'결과값을 기록할 df copy를 생성합니다.')\n","  for col in df.columns :\n","    max = df[col].max()\n","    debugLog(f'{col} column의 최대값을 기록합니다.')\n","    result[col] = df[col] / max\n","    debugLog(f'{col} 칼럼의 각 값을 {col} 칼럼의 최댓값으로 나눕니다.')\n","  debugLog(f'normalize() 를 종료합니다. 반환값은 \\n\\t df = \\n{result}')\n","  return result"],"metadata":{"id":"jrUHF88xCzkm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### [4-3] 학습, 테스트 데이터 분리 기능\n"],"metadata":{"id":"0dwZq_mP_cvn"}},{"cell_type":"code","source":["def splitData(df, train_portion) :\n","  debugLog(f'splitData() 를 시작합니다.')\n","  div = int(len(df) * train_portion)\n","  debugLog(f'train_portion의 비율대로 데이터를 나눌 수 있도록 index(data 개수 * portion)를 구해, 변수 div(={div})로 바인딩합니다.')\n","  train = df.iloc[:div]\n","  debugLog(f'train dataset을 train 변수로 바인딩합니다.')\n","  test = df.iloc[div:]\n","  debugLog(f'test dataset을 test 변수로 바인딩합니다.')\n","  debugLog(f'splitData() 를 종료합니다. 반환값은 \\n\\ttrain = \\n{train} \\n\\ttest = \\n{test} \\n입니다.')\n","  return train, test"],"metadata":{"id":"r2KVfFPR_eA7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## [5] 미니배치를 고려한 학습 데이터 기반의 신경망 연산 및 이진 판단 예측 기능\n"],"metadata":{"id":"MLSZEbhB_hGo"}},{"cell_type":"code","source":["def minibatch(df, batchSize) :\n","  debugLog(f'minibatch()를 시작합니다. 입렵값은 batchSize = {batchSize} \\n\\t df = \\n{df}')\n","  result = []\n","  debugLog(f'batchSize에 맞춰 자른 df들을 result 리스트에 append합니다.')\n","  count = len(df) // batchSize\n","  for i in range(count) :\n","    div = i*batchSize\n","    debugLog(f'{i} minibatch : df[{div}:{div+batchSize}]\\n{df[div:div+batchSize]}')\n","    result.append(df[div:div+batchSize])\n","  debugLog(f'minibatch()를 종료합니다. 반환값은 각 minibatch를 element로 갖는 리스트 입니다')\n","  return result  "],"metadata":{"id":"Qe2GMy4oj9DU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculForwardProp(df, weights, bias) :\n","  debugLog(f'calculForwardProp() 를 시작합니다.')\n","\n","  result = []\n","\n","  debugLog(f'\\n\\tweights = \\n{weights}')\n","  debugLog(f'\\n\\tbias = \\n{bias}')\n","  for index, row in df.iterrows():\n","    result.append(np.dot(row, weights) + bias)\n","    debugLog(f'sum({index} input * weight) + bias 의 결과를 reulst 리스트에 append 합니다.')\n","  \n","  debugLog(f'calculForwardProp() 를 종료합니다. 반환값은 \\n\\tweightSum = \\n{result}')\n","  return result"],"metadata":{"id":"1KwdFBo1_i3Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sigmoid(x):\n","  debugLog(f'sigmoid() 를 시작합니다.')\n","  debugLog(f'sigmoid() 를 종료합니다. 반환값은 입력값({x})의 sigmoid 함수 출력값 ({1 / (1 + np.exp(-x))}) 입니다')\n","  return 1 / (1 + np.exp(-x))"],"metadata":{"id":"cb-zpl1KfDra"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def forwardProp(df, weights, bias, batchSize): \n","  debugLog(f'forwardProp() 를 시작합니다.')\n","  batchs = minibatch(df, batchSize)\n","  result = [calculForwardProp(df, weights, bias) for df in batchs]\n","  tmp = []\n","  for weightsSums in result :\n","    x = []\n","    for sum in weightsSums:\n","      x.append(sigmoid(sum))\n","    tmp.append(x)\n","  result = tmp\n","  debugLog(f'minibatch 별로 weightSum을 구해, 하나의 리스트로 묶어 result에 append')\n","  debugLog(f'forwardProp() 를 종료합니다. 반환값은 \\n\\tsigmoid(weightsSums) \\n{result}입니다.')\n","  return result"],"metadata":{"id":"hBQgwQ8bk39v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## [6] 손실(교차 엔트로피)값 연산 기능\n"],"metadata":{"id":"_wK_JcJl_jY0"}},{"cell_type":"code","source":["def crossEntropyError(y, t):\n","  debugLog(f'crossEntropyError() 를 시작합니다.')\n","  debugLog(f'y가 0인 경우 -inf 값을 예방하기 위해, 아주 작은 값인 delta를 선언해 사용한다.')\n","  delta = 1e-7 #아주 작은 값 더하기 (y가 0인 경우 -inf 값을 예방)\n","  y = [x + delta for x in y]\n","  debugLog(f'crossEntropyError()를 종료합니다. 출력값(y, {y}), 예측값(t, {t}) 의 CEE값은 {-np.sum(t*np.log(y))}')\n","  return -np.sum(t*np.log(y))"],"metadata":{"id":"Hegu0yMJ_kuO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## [7] 정확도 연산 기능"],"metadata":{"id":"KOJ1d6pV_k_X"}},{"cell_type":"code","source":["def batchScore(y, t, threshold=0.5) :\n","  for i in range(len(y)) :\n","    if y[i] > threshold :\n","      y[i] = 1\n","    else :\n","      y[i] = 0\n","  \n","  answer = 0 \n","  for i in range(len(y)) :\n","    if y[i] == t.iloc[i] :\n","      answer += 1\n","\n","  return answer / len(y) \n"],"metadata":{"id":"W8t1ZvG0-WTI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## [8] 전체 기능의 동작 "],"metadata":{"id":"31TMOZNZ-6lu"}},{"cell_type":"code","source":["# 예시) **전체 기능의 동작 메서드 정의**\n","def main():\n","\n","  # 데이터 불러오기 기능\n","  df = dataLoad()\n","\n","  # Perceptron 생성\n","  weights, bias = createPerceptron(df)\n","\n","  # 데이터 뒤섞기\n","  df = shuffleDf(df)\n","\n","  # 데이터와 라벨 분리\n","  label = df.columns[-1]\n","  features = df.columns[:-1]\n","  x_df, y_df = divideLabelFeature(df, label, features)\n","  \n","  # 데이터 정규화\n","  x_df = normalize(x_df)\n","\n","  # train, test dataset 분리하기\n","  x_train, x_test = splitData(x_df, 0.8)\n","  y_train, y_test = splitData(y_df, 0.8)\n","\n","  # 순전파\n","  batchSize = 4\n","  result = forwardProp(x_train, weights, bias, batchSize)\n","\n","  # 손실 계산 \n","  loss = []\n","  for batch in range(len(result)):\n","    loss.append(crossEntropyError(result[batch], y_train[batch*batchSize:(batch+1)*batchSize]))\n","\n","  # 정확도 계산\n","  total_score = 0\n","  for batch in range(len(result)) :\n","    total_score += batchScore(result[batch], y_train[batch*batchSize:(batch+1)*batchSize])\n","  \n","  print(f'loss = {np.mean(loss)}, accuracy = {total_score/len(result)}')"],"metadata":{"id":"mF7e6Tn2DULp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKpuv6uLDi2z","executionInfo":{"status":"ok","timestamp":1673070602456,"user_tz":-540,"elapsed":557,"user":{"displayName":"최준영","userId":"05341350750950124905"}},"outputId":"6177da2c-5897-4e29-c454-0dc435b01b07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["debug_log | 2023.01.07 05:50:00 | >>> dataLoad() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> data 를 df 변수로 바인딩했습니다.\n","debug_log | 2023.01.07 05:50:00 | >>> dataLoad() 를 종료합니다. 반환값은 \n","\tdf = \n","            x1         x2        x3         x4          x5         x6         x7          x8  y\n","0   136.093750  51.691005 -0.045909  -0.271816    9.342809  38.096400   4.345438   18.673649  0\n","1    99.367188  41.572202  1.547197   4.154106   27.555184  61.719016   2.208808    3.662680  1\n","2   100.890625  51.890394  0.627487  -0.026498    3.883779  23.045267   6.953168   52.279440  0\n","3   120.554688  45.549905  0.282924   0.419909    1.358696  13.079034  13.312141  212.597029  1\n","4   121.882812  53.042675  0.200521  -0.282219    2.116221  16.580876   8.947603   91.011762  0\n","5   125.210938  51.175197  0.139851  -0.385737    1.147993  12.414012  14.068797  228.131554  0\n","6   141.968750  50.470898  0.244974  -0.342665    2.823579  16.238188   8.207744   85.532584  0\n","7   136.500000  49.932767  0.044623  -0.374311    1.555184  12.813538  13.314339  214.813089  0\n","8    83.679688  36.379281  0.572532   2.664611    4.040970  23.169129   7.006681   53.514005  0\n","9    27.765625  28.666042  5.770087  37.419009   73.112876  62.070220   1.268206    1.082920  1\n","10  135.859375  51.937272  0.065769  -0.366114   20.774247  52.772648   2.730909    6.607440  0\n","11  114.281250  41.253965  0.411821   0.616996    2.412207  20.427942   9.198392   88.370580  0\n","12  112.437500  38.295673  0.501943   1.074840    2.812709  18.136883   7.859968   71.299449  0\n","13   23.625000  29.948654  5.688038  35.987172  146.568562  82.394624  -0.274902   -1.121848  1\n","14   94.585938  35.779823  1.187309   3.687469    6.071070  29.760400   5.318767   28.698048  1\n","15  137.242188  46.454740  0.045257  -0.438858   59.495819  77.755357   0.719748   -1.183162  0\n","16  123.531250  53.348784  0.072078  -0.071601    0.781773  10.570833  17.118300  339.660826  0\n","17  123.468750  45.475085  0.345781   0.647415   32.919732  65.094197   1.605538    0.871364  1\n","18  103.523438  45.725739  0.336533   0.520558   11.289298  39.116453   3.509139   11.503980  0\n","19  107.929688  50.581954  0.320399   0.277613    2.022575  19.806556  10.472251  113.011537  0 \n"," 입니다.\n","debug_log | 2023.01.07 05:50:00 | >>> createPerceptron() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> 입력받은 df의 feature 개수를 featuresNum 변수에 바인딩합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> featuresNum의 수 만큼 weight 값을 난수(0~1 사이의 수)로 초기화합니다. 해당 값을 weights 변수로 바인딩합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> perceptron의 outputNode(1개) bias 값을 난수(0~1 사이의 수)로 초기화합니다. 해당 값을 bias 변수로 바인딩합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> craetePerceptron() 을 종료합니다. 반환값은 \n","\tWeights = [0.91127523 0.09000593 0.36436127 0.28834955 0.25584054 0.08002428\n"," 0.66402811 0.17576611], \n","\tBias = 0.9950655351855732) 입니다.\n","debug_log | 2023.01.07 05:50:00 | >>> shuffleDf() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> df를 shuffle하고 index를 초기화해 df로 재할당 합니다. 처리 전후 idx는 다음과 같습니다. \n","\tidx_i : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19] \n","\tidx_f : [13, 8, 14, 9, 15, 16, 3, 18, 0, 7, 2, 17, 12, 5, 4, 1, 6, 10, 19, 11]\n","debug_log | 2023.01.07 05:50:00 | >>> shuffleDf() 를 종료합니다. 반환값은 shuffle된 df 입니다.\n","debug_log | 2023.01.07 05:50:00 | >>> divideLabelFeature() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> features에 해당하는 데이터를 X 변수로 바인딩합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> label에 해당하는 데이터를 y 변수로 바인딩합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> divideLabelFeature() 를 종료합니다. 반환값은 \n","\tfeatures = \n","            x1         x2        x3         x4          x5         x6         x7          x8\n","0    23.625000  29.948654  5.688038  35.987172  146.568562  82.394624  -0.274902   -1.121848\n","1    83.679688  36.379281  0.572532   2.664611    4.040970  23.169129   7.006681   53.514005\n","2    94.585938  35.779823  1.187309   3.687469    6.071070  29.760400   5.318767   28.698048\n","3    27.765625  28.666042  5.770087  37.419009   73.112876  62.070220   1.268206    1.082920\n","4   137.242188  46.454740  0.045257  -0.438858   59.495819  77.755357   0.719748   -1.183162\n","5   123.531250  53.348784  0.072078  -0.071601    0.781773  10.570833  17.118300  339.660826\n","6   120.554688  45.549905  0.282924   0.419909    1.358696  13.079034  13.312141  212.597029\n","7   103.523438  45.725739  0.336533   0.520558   11.289298  39.116453   3.509139   11.503980\n","8   136.093750  51.691005 -0.045909  -0.271816    9.342809  38.096400   4.345438   18.673649\n","9   136.500000  49.932767  0.044623  -0.374311    1.555184  12.813538  13.314339  214.813089\n","10  100.890625  51.890394  0.627487  -0.026498    3.883779  23.045267   6.953168   52.279440\n","11  123.468750  45.475085  0.345781   0.647415   32.919732  65.094197   1.605538    0.871364\n","12  112.437500  38.295673  0.501943   1.074840    2.812709  18.136883   7.859968   71.299449\n","13  125.210938  51.175197  0.139851  -0.385737    1.147993  12.414012  14.068797  228.131554\n","14  121.882812  53.042675  0.200521  -0.282219    2.116221  16.580876   8.947603   91.011762\n","15   99.367188  41.572202  1.547197   4.154106   27.555184  61.719016   2.208808    3.662680\n","16  141.968750  50.470898  0.244974  -0.342665    2.823579  16.238188   8.207744   85.532584\n","17  135.859375  51.937272  0.065769  -0.366114   20.774247  52.772648   2.730909    6.607440\n","18  107.929688  50.581954  0.320399   0.277613    2.022575  19.806556  10.472251  113.011537\n","19  114.281250  41.253965  0.411821   0.616996    2.412207  20.427942   9.198392   88.370580 \n","\tlabel = \n","0     1\n","1     0\n","2     1\n","3     1\n","4     0\n","5     0\n","6     1\n","7     0\n","8     0\n","9     0\n","10    0\n","11    1\n","12    0\n","13    0\n","14    0\n","15    1\n","16    0\n","17    0\n","18    0\n","19    0\n","Name: y, dtype: int64\n","debug_log | 2023.01.07 05:50:00 | >>> normalize() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> 각 칼럼의 최댓값으로 열의 값들을 나눠 정규화합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> 결과값을 기록할 df copy를 생성합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> x1 column의 최대값을 기록합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> x1 칼럼의 각 값을 x1 칼럼의 최댓값으로 나눕니다.\n","debug_log | 2023.01.07 05:50:00 | >>> x2 column의 최대값을 기록합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> x2 칼럼의 각 값을 x2 칼럼의 최댓값으로 나눕니다.\n","debug_log | 2023.01.07 05:50:00 | >>> x3 column의 최대값을 기록합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> x3 칼럼의 각 값을 x3 칼럼의 최댓값으로 나눕니다.\n","debug_log | 2023.01.07 05:50:00 | >>> x4 column의 최대값을 기록합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> x4 칼럼의 각 값을 x4 칼럼의 최댓값으로 나눕니다.\n","debug_log | 2023.01.07 05:50:00 | >>> x5 column의 최대값을 기록합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> x5 칼럼의 각 값을 x5 칼럼의 최댓값으로 나눕니다.\n","debug_log | 2023.01.07 05:50:00 | >>> x6 column의 최대값을 기록합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> x6 칼럼의 각 값을 x6 칼럼의 최댓값으로 나눕니다.\n","debug_log | 2023.01.07 05:50:00 | >>> x7 column의 최대값을 기록합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> x7 칼럼의 각 값을 x7 칼럼의 최댓값으로 나눕니다.\n","debug_log | 2023.01.07 05:50:00 | >>> x8 column의 최대값을 기록합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> x8 칼럼의 각 값을 x8 칼럼의 최댓값으로 나눕니다.\n","debug_log | 2023.01.07 05:50:00 | >>> normalize() 를 종료합니다. 반환값은 \n","\t df = \n","          x1        x2        x3        x4        x5        x6        x7        x8\n","0   0.166410  0.561375  0.985780  0.961735  1.000000  1.000000 -0.016059 -0.003303\n","1   0.589423  0.681914  0.099224  0.071210  0.027571  0.281197  0.409309  0.157551\n","2   0.666245  0.670677  0.205770  0.098545  0.041421  0.361193  0.310706  0.084490\n","3   0.195576  0.537333  1.000000  1.000000  0.498831  0.753329  0.074085  0.003188\n","4   0.966707  0.870774  0.007843 -0.011728  0.405925  0.943695  0.042046 -0.003483\n","5   0.870130  1.000000  0.012492 -0.001913  0.005334  0.128295  1.000000  1.000000\n","6   0.849164  0.853813  0.049033  0.011222  0.009270  0.158737  0.777656  0.625910\n","7   0.729199  0.857109  0.058324  0.013912  0.077024  0.474745  0.204993  0.033869\n","8   0.958618  0.968926 -0.007956 -0.007264  0.063744  0.462365  0.253848  0.054977\n","9   0.961479  0.935968  0.007734 -0.010003  0.010611  0.155514  0.777784  0.632434\n","10  0.710654  0.972663  0.108748 -0.000708  0.026498  0.279694  0.406183  0.153917\n","11  0.869690  0.852411  0.059926  0.017302  0.224603  0.790030  0.093791  0.002565\n","12  0.791988  0.717836  0.086991  0.028724  0.019190  0.220122  0.459156  0.209914\n","13  0.881961  0.959257  0.024237 -0.010309  0.007832  0.150665  0.821857  0.671645\n","14  0.858519  0.994262  0.034752 -0.007542  0.014438  0.201237  0.522692  0.267949\n","15  0.699923  0.779253  0.268141  0.111016  0.188002  0.749066  0.129032  0.010783\n","16  1.000000  0.946055  0.042456 -0.009158  0.019265  0.197078  0.479472  0.251818\n","17  0.956967  0.973542  0.011398 -0.009784  0.141737  0.640487  0.159532  0.019453\n","18  0.760236  0.948137  0.055528  0.007419  0.013800  0.240387  0.611758  0.332719\n","19  0.804975  0.773288  0.071372  0.016489  0.016458  0.247928  0.537343  0.260173\n","debug_log | 2023.01.07 05:50:00 | >>> splitData() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> train_portion의 비율대로 데이터를 나눌 수 있도록 index(data 개수 * portion)를 구해, 변수 div(=16)로 바인딩합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> train dataset을 train 변수로 바인딩합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> test dataset을 test 변수로 바인딩합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> splitData() 를 종료합니다. 반환값은 \n","\ttrain = \n","          x1        x2        x3        x4        x5        x6        x7        x8\n","0   0.166410  0.561375  0.985780  0.961735  1.000000  1.000000 -0.016059 -0.003303\n","1   0.589423  0.681914  0.099224  0.071210  0.027571  0.281197  0.409309  0.157551\n","2   0.666245  0.670677  0.205770  0.098545  0.041421  0.361193  0.310706  0.084490\n","3   0.195576  0.537333  1.000000  1.000000  0.498831  0.753329  0.074085  0.003188\n","4   0.966707  0.870774  0.007843 -0.011728  0.405925  0.943695  0.042046 -0.003483\n","5   0.870130  1.000000  0.012492 -0.001913  0.005334  0.128295  1.000000  1.000000\n","6   0.849164  0.853813  0.049033  0.011222  0.009270  0.158737  0.777656  0.625910\n","7   0.729199  0.857109  0.058324  0.013912  0.077024  0.474745  0.204993  0.033869\n","8   0.958618  0.968926 -0.007956 -0.007264  0.063744  0.462365  0.253848  0.054977\n","9   0.961479  0.935968  0.007734 -0.010003  0.010611  0.155514  0.777784  0.632434\n","10  0.710654  0.972663  0.108748 -0.000708  0.026498  0.279694  0.406183  0.153917\n","11  0.869690  0.852411  0.059926  0.017302  0.224603  0.790030  0.093791  0.002565\n","12  0.791988  0.717836  0.086991  0.028724  0.019190  0.220122  0.459156  0.209914\n","13  0.881961  0.959257  0.024237 -0.010309  0.007832  0.150665  0.821857  0.671645\n","14  0.858519  0.994262  0.034752 -0.007542  0.014438  0.201237  0.522692  0.267949\n","15  0.699923  0.779253  0.268141  0.111016  0.188002  0.749066  0.129032  0.010783 \n","\ttest = \n","          x1        x2        x3        x4        x5        x6        x7        x8\n","16  1.000000  0.946055  0.042456 -0.009158  0.019265  0.197078  0.479472  0.251818\n","17  0.956967  0.973542  0.011398 -0.009784  0.141737  0.640487  0.159532  0.019453\n","18  0.760236  0.948137  0.055528  0.007419  0.013800  0.240387  0.611758  0.332719\n","19  0.804975  0.773288  0.071372  0.016489  0.016458  0.247928  0.537343  0.260173 \n","입니다.\n","debug_log | 2023.01.07 05:50:00 | >>> splitData() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> train_portion의 비율대로 데이터를 나눌 수 있도록 index(data 개수 * portion)를 구해, 변수 div(=16)로 바인딩합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> train dataset을 train 변수로 바인딩합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> test dataset을 test 변수로 바인딩합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> splitData() 를 종료합니다. 반환값은 \n","\ttrain = \n","0     1\n","1     0\n","2     1\n","3     1\n","4     0\n","5     0\n","6     1\n","7     0\n","8     0\n","9     0\n","10    0\n","11    1\n","12    0\n","13    0\n","14    0\n","15    1\n","Name: y, dtype: int64 \n","\ttest = \n","16    0\n","17    0\n","18    0\n","19    0\n","Name: y, dtype: int64 \n","입니다.\n","debug_log | 2023.01.07 05:50:00 | >>> forwardProp() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> minibatch()를 시작합니다. 입렵값은 batchSize = 4 \n","\t df = \n","          x1        x2        x3        x4        x5        x6        x7        x8\n","0   0.166410  0.561375  0.985780  0.961735  1.000000  1.000000 -0.016059 -0.003303\n","1   0.589423  0.681914  0.099224  0.071210  0.027571  0.281197  0.409309  0.157551\n","2   0.666245  0.670677  0.205770  0.098545  0.041421  0.361193  0.310706  0.084490\n","3   0.195576  0.537333  1.000000  1.000000  0.498831  0.753329  0.074085  0.003188\n","4   0.966707  0.870774  0.007843 -0.011728  0.405925  0.943695  0.042046 -0.003483\n","5   0.870130  1.000000  0.012492 -0.001913  0.005334  0.128295  1.000000  1.000000\n","6   0.849164  0.853813  0.049033  0.011222  0.009270  0.158737  0.777656  0.625910\n","7   0.729199  0.857109  0.058324  0.013912  0.077024  0.474745  0.204993  0.033869\n","8   0.958618  0.968926 -0.007956 -0.007264  0.063744  0.462365  0.253848  0.054977\n","9   0.961479  0.935968  0.007734 -0.010003  0.010611  0.155514  0.777784  0.632434\n","10  0.710654  0.972663  0.108748 -0.000708  0.026498  0.279694  0.406183  0.153917\n","11  0.869690  0.852411  0.059926  0.017302  0.224603  0.790030  0.093791  0.002565\n","12  0.791988  0.717836  0.086991  0.028724  0.019190  0.220122  0.459156  0.209914\n","13  0.881961  0.959257  0.024237 -0.010309  0.007832  0.150665  0.821857  0.671645\n","14  0.858519  0.994262  0.034752 -0.007542  0.014438  0.201237  0.522692  0.267949\n","15  0.699923  0.779253  0.268141  0.111016  0.188002  0.749066  0.129032  0.010783\n","debug_log | 2023.01.07 05:50:00 | >>> batchSize에 맞춰 자른 df들을 result 리스트에 append합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> 0 minibatch : df[0:4]\n","         x1        x2        x3        x4        x5        x6        x7        x8\n","0  0.166410  0.561375  0.985780  0.961735  1.000000  1.000000 -0.016059 -0.003303\n","1  0.589423  0.681914  0.099224  0.071210  0.027571  0.281197  0.409309  0.157551\n","2  0.666245  0.670677  0.205770  0.098545  0.041421  0.361193  0.310706  0.084490\n","3  0.195576  0.537333  1.000000  1.000000  0.498831  0.753329  0.074085  0.003188\n","debug_log | 2023.01.07 05:50:00 | >>> 1 minibatch : df[4:8]\n","         x1        x2        x3        x4        x5        x6        x7        x8\n","4  0.966707  0.870774  0.007843 -0.011728  0.405925  0.943695  0.042046 -0.003483\n","5  0.870130  1.000000  0.012492 -0.001913  0.005334  0.128295  1.000000  1.000000\n","6  0.849164  0.853813  0.049033  0.011222  0.009270  0.158737  0.777656  0.625910\n","7  0.729199  0.857109  0.058324  0.013912  0.077024  0.474745  0.204993  0.033869\n","debug_log | 2023.01.07 05:50:00 | >>> 2 minibatch : df[8:12]\n","          x1        x2        x3        x4        x5        x6        x7        x8\n","8   0.958618  0.968926 -0.007956 -0.007264  0.063744  0.462365  0.253848  0.054977\n","9   0.961479  0.935968  0.007734 -0.010003  0.010611  0.155514  0.777784  0.632434\n","10  0.710654  0.972663  0.108748 -0.000708  0.026498  0.279694  0.406183  0.153917\n","11  0.869690  0.852411  0.059926  0.017302  0.224603  0.790030  0.093791  0.002565\n","debug_log | 2023.01.07 05:50:00 | >>> 3 minibatch : df[12:16]\n","          x1        x2        x3        x4        x5        x6        x7        x8\n","12  0.791988  0.717836  0.086991  0.028724  0.019190  0.220122  0.459156  0.209914\n","13  0.881961  0.959257  0.024237 -0.010309  0.007832  0.150665  0.821857  0.671645\n","14  0.858519  0.994262  0.034752 -0.007542  0.014438  0.201237  0.522692  0.267949\n","15  0.699923  0.779253  0.268141  0.111016  0.188002  0.749066  0.129032  0.010783\n","debug_log | 2023.01.07 05:50:00 | >>> minibatch()를 종료합니다. 반환값은 각 minibatch를 element로 갖는 리스트 입니다\n","debug_log | 2023.01.07 05:50:00 | >>> calculForwardProp() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> \n","\tweights = \n","[0.91127523 0.09000593 0.36436127 0.28834955 0.25584054 0.08002428\n"," 0.66402811 0.17576611]\n","debug_log | 2023.01.07 05:50:00 | >>> \n","\tbias = \n","0.9950655351855732\n","debug_log | 2023.01.07 05:50:00 | >>> sum(0 input * weight) + bias 의 결과를 reulst 리스트에 append 합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sum(1 input * weight) + bias 의 결과를 reulst 리스트에 append 합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sum(2 input * weight) + bias 의 결과를 reulst 리스트에 append 합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sum(3 input * weight) + bias 의 결과를 reulst 리스트에 append 합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> calculForwardProp() 를 종료합니다. 반환값은 \n","\tweightSum = \n","[2.158354481593415, 1.9792968849601857, 2.0266227094788873, 2.112023116636699]\n","debug_log | 2023.01.07 05:50:00 | >>> calculForwardProp() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> \n","\tweights = \n","[0.91127523 0.09000593 0.36436127 0.28834955 0.25584054 0.08002428\n"," 0.66402811 0.17576611]\n","debug_log | 2023.01.07 05:50:00 | >>> \n","\tbias = \n","0.9950655351855732\n","debug_log | 2023.01.07 05:50:00 | >>> sum(4 input * weight) + bias 의 결과를 reulst 리스트에 append 합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sum(5 input * weight) + bias 의 결과를 reulst 리스트에 append 합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sum(6 input * weight) + bias 의 결과를 reulst 리스트에 append 합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sum(7 input * weight) + bias 의 결과를 reulst 리스트에 append 합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> calculForwardProp() 를 종료합니다. 반환값은 \n","\tweightSum = \n","[2.1605302071404804, 2.733424522077964, 2.5083103151803408, 1.9617449961533788]\n","debug_log | 2023.01.07 05:50:00 | >>> calculForwardProp() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> \n","\tweights = \n","[0.91127523 0.09000593 0.36436127 0.28834955 0.25584054 0.08002428\n"," 0.66402811 0.17576611]\n","debug_log | 2023.01.07 05:50:00 | >>> \n","\tbias = \n","0.9950655351855732\n","debug_log | 2023.01.07 05:50:00 | >>> sum(8 input * weight) + bias 의 결과를 reulst 리스트에 append 합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sum(9 input * weight) + bias 의 결과를 reulst 리스트에 append 합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sum(10 input * weight) + bias 의 결과를 reulst 리스트에 append 합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sum(11 input * weight) + bias 의 결과를 reulst 리스트에 append 합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> calculForwardProp() 를 종료합니다. 반환값은 \n","\tweightSum = \n","[2.182379192919339, 2.598204225952182, 2.095563606102212, 2.074552715708515]\n","debug_log | 2023.01.07 05:50:00 | >>> calculForwardProp() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> \n","\tweights = \n","[0.91127523 0.09000593 0.36436127 0.28834955 0.25584054 0.08002428\n"," 0.66402811 0.17576611]\n","debug_log | 2023.01.07 05:50:00 | >>> \n","\tbias = \n","0.9950655351855732\n","debug_log | 2023.01.07 05:50:00 | >>> sum(12 input * weight) + bias 의 결과를 reulst 리스트에 append 합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sum(13 input * weight) + bias 의 결과를 reulst 리스트에 append 합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sum(14 input * weight) + bias 의 결과를 reulst 리스트에 append 합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sum(15 input * weight) + bias 의 결과를 reulst 리스트에 append 합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> calculForwardProp() 를 종료합니다. 반환값은 \n","\tweightSum = \n","[2.1856854017557277, 2.568821929843982, 2.2913656928578297, 2.028355176437741]\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 종료합니다. 반환값은 입력값(2.158354481593415)의 sigmoid 함수 출력값 (0.8964468949189114) 입니다\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 종료합니다. 반환값은 입력값(1.9792968849601857)의 sigmoid 함수 출력값 (0.8786061896801934) 입니다\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 종료합니다. 반환값은 입력값(2.0266227094788873)의 sigmoid 함수 출력값 (0.8835640768515151) 입니다\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 종료합니다. 반환값은 입력값(2.112023116636699)의 sigmoid 함수 출력값 (0.892066281628331) 입니다\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 종료합니다. 반환값은 입력값(2.1605302071404804)의 sigmoid 함수 출력값 (0.8966486930732275) 입니다\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 종료합니다. 반환값은 입력값(2.733424522077964)의 sigmoid 함수 출력값 (0.9389703747081227) 입니다\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 종료합니다. 반환값은 입력값(2.5083103151803408)의 sigmoid 함수 출력값 (0.9247223543776207) 입니다\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 종료합니다. 반환값은 입력값(1.9617449961533788)의 sigmoid 함수 출력값 (0.876721676992247) 입니다\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 종료합니다. 반환값은 입력값(2.182379192919339)의 sigmoid 함수 출력값 (0.8986559589639721) 입니다\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 종료합니다. 반환값은 입력값(2.598204225952182)의 sigmoid 함수 출력값 (0.9307459172328219) 입니다\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 종료합니다. 반환값은 입력값(2.095563606102212)의 sigmoid 함수 출력값 (0.8904712364429054) 입니다\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 종료합니다. 반환값은 입력값(2.074552715708515)의 sigmoid 함수 출력값 (0.8884051231025014) 입니다\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 종료합니다. 반환값은 입력값(2.1856854017557277)의 sigmoid 함수 출력값 (0.8989566701078427) 입니다\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 종료합니다. 반환값은 입력값(2.568821929843982)의 sigmoid 함수 출력값 (0.9288278569541452) 입니다\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 종료합니다. 반환값은 입력값(2.2913656928578297)의 sigmoid 함수 출력값 (0.9081594204055793) 입니다\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> sigmoid() 를 종료합니다. 반환값은 입력값(2.028355176437741)의 sigmoid 함수 출력값 (0.883742192220601) 입니다\n","debug_log | 2023.01.07 05:50:00 | >>> minibatch 별로 weightSum을 구해, 하나의 리스트로 묶어 result에 append\n","debug_log | 2023.01.07 05:50:00 | >>> forwardProp() 를 종료합니다. 반환값은 \n","\tsigmoid(weightsSums) \n","[[0.8964468949189114, 0.8786061896801934, 0.8835640768515151, 0.892066281628331], [0.8966486930732275, 0.9389703747081227, 0.9247223543776207, 0.876721676992247], [0.8986559589639721, 0.9307459172328219, 0.8904712364429054, 0.8884051231025014], [0.8989566701078427, 0.9288278569541452, 0.9081594204055793, 0.883742192220601]]입니다.\n","debug_log | 2023.01.07 05:50:00 | >>> crossEntropyError() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> y가 0인 경우 -inf 값을 예방하기 위해, 아주 작은 값인 delta를 선언해 사용한다.\n","debug_log | 2023.01.07 05:50:00 | >>> crossEntropyError()를 종료합니다. 출력값(y, [0.8964469949189113, 0.8786062896801934, 0.883564176851515, 0.892066381628331]), 예측값(t, 0    1\n","1    0\n","2    1\n","3    1\n","Name: y, dtype: int64) 의 CEE값은 0.34732219297969025\n","debug_log | 2023.01.07 05:50:00 | >>> crossEntropyError() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> y가 0인 경우 -inf 값을 예방하기 위해, 아주 작은 값인 delta를 선언해 사용한다.\n","debug_log | 2023.01.07 05:50:00 | >>> crossEntropyError()를 종료합니다. 출력값(y, [0.8966487930732274, 0.9389704747081227, 0.9247224543776207, 0.876721776992247]), 예측값(t, 4    0\n","5    0\n","6    1\n","7    0\n","Name: y, dtype: int64) 의 CEE값은 0.07826163581500714\n","debug_log | 2023.01.07 05:50:00 | >>> crossEntropyError() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> y가 0인 경우 -inf 값을 예방하기 위해, 아주 작은 값인 delta를 선언해 사용한다.\n","debug_log | 2023.01.07 05:50:00 | >>> crossEntropyError()를 종료합니다. 출력값(y, [0.898656058963972, 0.9307460172328218, 0.8904713364429053, 0.8884052231025014]), 예측값(t, 8     0\n","9     0\n","10    0\n","11    1\n","Name: y, dtype: int64) 의 CEE값은 0.11832730775526007\n","debug_log | 2023.01.07 05:50:00 | >>> crossEntropyError() 를 시작합니다.\n","debug_log | 2023.01.07 05:50:00 | >>> y가 0인 경우 -inf 값을 예방하기 위해, 아주 작은 값인 delta를 선언해 사용한다.\n","debug_log | 2023.01.07 05:50:00 | >>> crossEntropyError()를 종료합니다. 출력값(y, [0.8989567701078427, 0.9288279569541451, 0.9081595204055792, 0.883742292220601]), 예측값(t, 12    0\n","13    0\n","14    0\n","15    1\n","Name: y, dtype: int64) 의 CEE값은 0.1235897834833903\n","loss = 0.16687523000833693, accuracy = 0.375\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"n334","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.13 (default, Mar 28 2022, 01:56:06) [MSC v.1916 32 bit (Intel)]"},"vscode":{"interpreter":{"hash":"a782b353a3a4019c1317d6945f310285c8e4ca368108bb1fe389ffe2a0f21209"}}},"nbformat":4,"nbformat_minor":0}